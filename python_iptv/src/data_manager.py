import os
import gzip
import requests
import xml.etree.ElementTree as ET
from datetime import datetime, timezone
import io
import re
import logging
import sys

class DataManager:
    def __init__(self):
        self.channels = []
        self.epg_data = {}  # {channel_id: [programs]}
        self.epg_channels = {} # {id: name}
        self.epg_names = {} # {id: display_name}
        self.epg_icons = {} # {id: icon_src}
        self.user_agent = "VAVOO/2.6" # Default backup
        self.logos_map = {} # {norm_name: logo_path}
        
        self._load_local_logos()

    def _load_local_logos(self):
        """Scans the logos directory and builds a map."""
        logos_dir = os.path.join(os.path.dirname(__file__), "..", "..", "logos")
        if not os.path.exists(logos_dir):
            return
        
        for filename in os.listdir(logos_dir):
            if filename.endswith(('.png', '.svg', '.jpg')):
                # Normalize filename for matching
                # Remove extension and replace hyphens/underscores with spaces
                base = os.path.splitext(filename)[0]
                norm_base = re.sub(r'[^A-Z0-9]', '', base.upper())
                # Also handle common patterns like '-it' at the end
                norm_base = re.sub(r'IT$', '', norm_base)
                self.logos_map[norm_base] = os.path.join(logos_dir, filename)

    def find_logo(self, norm_name):
        """Attempts to find a matching logo path."""
        if not norm_name: return None
        # Try direct match
        snorm = re.sub(r'[^A-Z0-9]', '', norm_name)
        if snorm in self.logos_map:
            return self.logos_map[snorm]
        
        # Try partial matches
        for key in self.logos_map:
            if key in snorm or snorm in key:
                return self.logos_map[key]
        return None

    def get_clean_epg_name(self, epg_id):
        """Returns the display name from EPG, stripping 'IT - ' prefix."""
        if not epg_id: return None
        raw_name = self.epg_names.get(epg_id)
        if not raw_name: return None
        
        # Remove "IT - " or "CH - " prefix if present
        clean_name = re.sub(r'^(IT|CH)\s*-\s*', '', raw_name, flags=re.IGNORECASE)
        return clean_name.strip()

    def normalize_name(self, name):
        """Normalizes channel name for better EPG matching."""
        if not name: return ""
        n = name.upper().strip()
        
        # Remove explicit country codes or extensions if at end e.g. " .IT", " .c"
        # Matches space + dot + 1-3 letters
        n = re.sub(r'\s+\.[A-Z]{1,3}$', '', n)
        
        # Remove Vavoo specific suffixes " C", " S", " T" if they appear without dot
        n = re.sub(r'\s+[CST]$', '', n)
        
        # Remove parentheses/brackets
        n = re.sub(r'\[.*?\]', '', n)
        n = re.sub(r'\(.*?\)', '', n)
        
        # Specific fix for "Rai 1 HD 101" -> "RAI 1"
        # Remove "HD", "FHD", "SD", "HEVC", "H265", and all text following it
        # KEEP 4K to distinguish Rai 4K
        n = re.sub(r'\s+(HD|FHD|SD|HEVC|H265).*', '', n)
        
        # Remove special chars AND spaces (e.g. "Rai 1" -> "RAI1" matches EPG "Rai1")
        n = re.sub(r'[^A-Z0-9]', '', n)
        
        n = n.strip()
        # logging.debug(f"NORM: '{name}' -> '{n}'")
        return n

    def parse_m3u8(self, file_path):
        """Parses the local M3U8 file generated by the skill."""
        self.channels = []
        epg_url = None
        
        try:
            logging.info(f"Parsing playlist: {file_path}")
            if not os.path.exists(file_path):
                logging.error(f"File not found: {file_path}")
                return [], None

            with open(file_path, 'r', encoding='utf-8-sig') as f:
                lines = f.readlines()
            
            current_channel = {}
            
            for line in lines:
                line = line.strip()
                
                if line.startswith("#EXTM3U"):
                    if 'x-tvg-url="' in line:
                        epg_url = line.split('x-tvg-url="')[1].split('"')[0]
                
                elif line.startswith("#EXTINF:"):
                    current_channel = {}
                    
                    # Extract tvg-id
                    match_id = re.search(r'tvg-id="([^"]*)"', line)
                    current_channel['id'] = match_id.group(1) if match_id else None
                        
                    # Extract Logo
                    match_logo = re.search(r'tvg-logo="([^"]*)"', line)
                    current_channel['logo'] = match_logo.group(1) if match_logo else None
                    
                    # Extract Name
                    raw_name = line.split(',')[-1].strip()
                    current_channel['name'] = raw_name
                    current_channel['norm_name'] = self.normalize_name(raw_name)

                    # Extract Group
                    match_group = re.search(r'group-title="([^"]*)"', line)
                    current_channel['group'] = match_group.group(1) if match_group else "Uncategorized"
                    
                    
                elif line.startswith("#EXTVLCOPT:http-user-agent="):
                    self.user_agent = line.split('=')[1].strip()
                    
                elif line.startswith("http"):
                    if current_channel:
                        current_channel['url'] = line
                        current_channel['user_agent'] = self.user_agent
                        # If ID is missing, use normalized name
                        if not current_channel.get('id'):
                            current_channel['id'] = current_channel['norm_name']
                        self.channels.append(current_channel)
                        current_channel = {}
            
            logging.info(f"Found {len(self.channels)} channels and EPG: {epg_url}")
            return self.channels, epg_url
            
        except Exception as e:
            logging.error(f"Error parsing playlist: {e}")
            return [], None

    def load_all_epgs(self):
        """Loads EPG data from multiple sources with backup fallback."""
        epg_sources = [
            {
                "name": "Italy",
                "primary": "https://iptv-epg.org/files/epg-it.xml.gz",
                "backup": "https://epgshare01.online/epgshare01/epg_ripper_IT1.xml.gz"
            },
            {
                "name": "Swiss (RSI)",
                "primary": "https://iptv-epg.org/files/epg-ch.xml.gz",
                "backup": "https://epgshare01.online/epgshare01/epg_ripper_CH1.xml.gz"
            }
        ]

        for source in epg_sources:
            logging.info(f"--- Loading EPG Source: {source['name']} ---")
            
            # Try Primary
            try:
                self._fetch_and_parse_epg(source['primary'], source['name'])
            except Exception as e:
                logging.warning(f"Primary EPG failed for {source['name']}: {e}")
                
            # Try Backup (Supplement/Merge)
            if source.get('backup'):
                logging.info(f"Loading backup EPG for {source['name']} to supplement data...")
                try:
                    self._fetch_and_parse_epg(source['backup'], source['name'])
                except Exception as e2:
                    logging.error(f"Backup EPG failed for {source['name']}: {e2}")
        
        # After loading all, apply mappings to channels
        self._apply_epg_to_channels()

    def _fetch_and_parse_epg(self, url, source_name=""):
        """Downloads and parses a single XMLTV GZ file, merging into storage."""
        if not url: return

        logging.info(f"Downloading EPG from {url}...")
        
        headers = {'User-Agent': self.user_agent}
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        
        # Download
        with requests.get(url, headers=headers, timeout=15, verify=False, stream=True) as response:
            response.raise_for_status()
            total_length = response.headers.get('content-length')
            
            if total_length is None:
                content = response.content
            else:
                dl = 0
                total_length = int(total_length)
                content = b''
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        content += chunk
                        dl += len(chunk)
                        # Minimal progress feedback
        
        logging.info(f"Download complete. Size: {len(content)} bytes.")
        
        if len(content) < 1024:
            raise Exception(f"Downloaded EPG is too small ({len(content)} bytes). Assuming failure.")

        logging.info("Decompressing EPG...")
        # Handle both .gz and plain .xml
        if url.endswith('.gz'):
             with gzip.GzipFile(fileobj=io.BytesIO(content)) as gz:
                xml_content = gz.read()
        else:
             xml_content = content
            
        logging.info("Parsing XML EPG...")
        root = ET.fromstring(xml_content)
        
        # MERGE: Store channel names (Append/Update)
        count_ch = 0
        for channel in root.findall('channel'):
            c_id = channel.get('id')
            display_name = channel.find('display-name')
            if c_id and display_name is not None:
                dname_text = display_name.text

                # FILTER: Swiss Channels (RSI Only to avoid bloat)
                if "Swiss" in source_name or "RSI" in source_name:
                    norm_curr = self.normalize_name(dname_text)
                    if norm_curr not in ["RSILA1", "RSILA2"]:
                        continue

                self.epg_channels[c_id] = dname_text
                # Also map normalized name to ID
                norm = self.normalize_name(dname_text)
                self.epg_channels[norm] = c_id
                self.epg_names[c_id] = dname_text
                
                # EXTRACT ICON
                icon = channel.find('icon')
                if icon is not None:
                    src = icon.get('src')
                    if src:
                        self.epg_icons[c_id] = src
                count_ch += 1
                
        logging.info(f"Merged {count_ch} channel names from this source.")
        
        # MERGE: Store Programs
        count_prog = 0
        for programme in root.findall('programme'):
            channel_id = programme.get('channel')
            start_str = programme.get('start')
            stop_str = programme.get('stop')
            
            title_el = programme.find('title')
            title = title_el.text if title_el is not None else "N/A"
            
            desc_el = programme.find('desc')
            desc = desc_el.text if desc_el is not None else ""
            
            if channel_id not in self.epg_data:
                self.epg_data[channel_id] = []
                
            self.epg_data[channel_id].append({
                'start': start_str,
                'stop': stop_str,
                'title': title,
                'desc': desc
            })
            count_prog += 1
            
        logging.info(f"Merged {count_prog} programs from this source.")

    def _apply_epg_to_channels(self):
        """Updates channel names based on loaded EPG data."""
        matches = 0
        for ch in self.channels:
            # Look up EPG ID using normalized name
            norm = ch.get('norm_name')
            epg_id = self.epg_channels.get(norm)
            
            if epg_id:
                # Get official display name
                real_name = self.epg_names.get(epg_id)
                if real_name:
                    ch['name'] = real_name
                    matches += 1
                
                # Apply EPG Icon if available
                epg_icon = self.epg_icons.get(epg_id)
                if epg_icon:
                    ch['logo'] = epg_icon
        
        logging.info(f"Updated {matches} channel names from all EPGs.")

    # Legacy method kept for compatibility
    def load_epg(self, url):
        self._fetch_and_parse_epg(url)
        self._apply_epg_to_channels()

    def get_current_program(self, channel_id, norm_name=None):
        """Finds the current running program using ID or normalized name.
        Returns: (title, desc, start_dt, stop_dt) or (None, None, None, None)
        """
        now = datetime.now(timezone.utc)
        
        # Try direct ID
        target_id = channel_id
        
        # If no programs for this ID, try finding ID via normalized name
        if target_id not in self.epg_data and norm_name:
            target_id = self.epg_channels.get(norm_name)
            
        if not target_id or target_id not in self.epg_data:
            if norm_name and "RAI" in norm_name:
                logging.warning(f"EPG MISS: Channel '{norm_name}' not found in EPG (Found ID: {target_id})")
            return None, None, None, None
            
        programs = self.epg_data[target_id]
        for prog in programs:
            try:
                start_dt = self._parse_xmltv_date(prog['start'])
                stop_dt = self._parse_xmltv_date(prog['stop'])
                
                if start_dt and stop_dt and start_dt <= now <= stop_dt:
                    return prog['title'], prog['desc'], start_dt, stop_dt
            except:
                continue
                
        return "No Info Available", "", None, None

    def _parse_xmltv_date(self, date_str):
        try:
            return datetime.strptime(date_str, "%Y%m%d%H%M%S %z")
        except:
            return None

